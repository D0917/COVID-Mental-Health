{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import r2_score\n",
    "from rfpimp import permutation_importances\n",
    "from sklearn.impute import KNNImputer\n",
    "import missingpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"COVID_data.csv\", sep=',', error_bad_lines=False, index_col=False, dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Questions:\n",
    "    \n",
    "    # The init function\n",
    "    def __init__(self, row):\n",
    "        self.q = row.drop(columns=['SU_ID', 'P_PANEL', 'P_GEO', 'AGE4', 'AGE7', 'GENDER', 'RACETH', 'RACE_R2', 'HHINCOME', 'EDUCATION', 'EDUC4', 'P_OCCUPY', 'MARITAL', 'LGBT', 'HHSIZE1', 'HH01S', 'HH25S', 'HH612S', 'HH1317S', 'H180VS', 'REGION4', 'REGION9', 'P_DENSE', 'MODE', 'LANGUAGE', 'MAIL50', 'RACE1_BANNER', 'RACE2_BANNER', 'INC_BANNER', 'AGE_BANNER', 'HH_BANNER'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patient:\n",
    "        \n",
    "    # The init function\n",
    "    def __init__(self, row):\n",
    "        self.name = row['SU_ID']\n",
    "        self.age = row['AGE4']\n",
    "        self.race = row['RACE1_BANNER']\n",
    "        self.gender = row['GENDER']        \n",
    "        self.income = row['HHINCOME']\n",
    "        self.edu = row['EDUCATION']\n",
    "        self.loc = row['P_GEO']\n",
    "        self.size = row['HH_BANNER'] #size is household size\n",
    "        self.q = Questions(row)\n",
    "\n",
    "p = []        \n",
    "        \n",
    "for i in range(len(df)):\n",
    "    my_patient = Patient(df.iloc[i])\n",
    "    p.append(my_patient)\n",
    "    #print (\"My patient is {}\".format(my_patient.name) + \" and is {}\".format(my_patient.age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('ABS', 1).replace('Amerispeak', 0).drop(columns=['RACE_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_number(df):\n",
    "    for column in df.columns[2:]:\n",
    "        for i in df[column]:\n",
    "            if type(i) == str and i.startswith('('):\n",
    "                df[column] = df[column].replace(i, i[1:i.index(')')])\n",
    "            if type(i) == float:\n",
    "                pass\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_number(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## changing strings in column to integers\n",
    "def change_str_to_int(df, column):\n",
    "    for i in df[column]:\n",
    "        if i.startswith('Under'):\n",
    "            df[column] = df[column].replace(i, '1')\n",
    "        elif i.startswith('$10,000'):\n",
    "            df[column] = df[column].replace(i, '2')\n",
    "        elif i.startswith('$20,000'):\n",
    "            df[column] = df[column].replace(i, '3')\n",
    "        elif i.startswith('$30,000'):\n",
    "            df[column] = df[column].replace(i, '4')\n",
    "        elif i.startswith('$40,000'):\n",
    "            df[column] = df[column].replace(i, '5')   \n",
    "        elif i.startswith('$50,000'):\n",
    "            df[column] = df[column].replace(i, '6')  \n",
    "        elif i.startswith('$75,000'): \n",
    "            df[column] = df[column].replace(i, '7')\n",
    "        elif i.startswith('$100,000'):\n",
    "            df[column] = df[column].replace(i, '8') \n",
    "        elif i.startswith('$150,000'):\n",
    "            df[column] = df[column].replace(i, '9')    \n",
    "        elif i.startswith('DO'):\n",
    "            df[column] = df[column].replace(i, '10')\n",
    "        elif i.startswith('SKIPPED'):\n",
    "            df[column] = df[column].replace(i, '11')\n",
    "        elif i.startswith('REFUSED'):\n",
    "            df[column] = df[column].replace(i, '12')\n",
    "    return (df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_str_to_int(df, 'HHINCOME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix missing data issue\n",
    "for i in range(len(df)):\n",
    "    num = np.random.randint(0,100)\n",
    "    if num > 100:\n",
    "        df[i][np.random.randint(0,4)] = float(\"NaN\")\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = missingpy.MissForest()\n",
    "all_data = imputer.fit_transform(df)\n",
    "\n",
    "### we can see there are no more nan values\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change numpy array to dataframe\n",
    "\n",
    "df = pd.DataFrame(data=all_data, index=df.index, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the dataset \n",
    "def splitdataset(df, illness = 'SOC5A'): \n",
    "  \n",
    "    # Separating the target variable \n",
    "    X = df.drop(columns =['SOC5A', 'SOC5B', 'SOC5C', 'SOC5D', 'SOC5E']).values\n",
    "    Y = df[illness].values\n",
    "    \n",
    "    # The variable X contains everything but responses to the question on mental health\n",
    "    # The variable Y is the target variable, responses on anxiety levels\n",
    "\n",
    "    # Splitting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 100) \n",
    "    \n",
    "    # Splitting the dataset in a ratio of 80:20 between training and testing \n",
    "    # random_state variable = pseudo-random # generator used for random sampling\n",
    "    \n",
    "    return X, Y, X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function\n",
    "X, y, X_train, X_test, y_train, y_test = splitdataset(df) \n",
    "# Fit the classifier with default hyper-parameters\n",
    "clf = DecisionTreeClassifier(random_state=1234, max_depth=2)\n",
    "model = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(clf, \n",
    "                   feature_names=df.columns.drop(['SOC5A', 'SOC5B', 'SOC5C', 'SOC5D', 'SOC5E']),  \n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"decistion_tree.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train) # trains algorithm on training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform training with giniIndex. \n",
    "def train_using_gini(X_train, X_test, y_train): \n",
    "  \n",
    "    # Creating the classifier object \n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            random_state = 100,max_depth=3, min_samples_leaf=5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform training with entropy. \n",
    "def train_using_entropy(X_train, X_test, y_train): \n",
    "  \n",
    "    # Decision tree with entropy \n",
    "    clf_entropy = DecisionTreeClassifier( \n",
    "            criterion = \"entropy\", random_state = 100, \n",
    "            max_depth = 3, min_samples_leaf = 5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_entropy.fit(X_train, y_train) \n",
    "    return clf_entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Predicton on test with giniIndex \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\") \n",
    "    print(y_pred) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "      \n",
    "    print(\"Report : \", \n",
    "    classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Phase \n",
    "data = df\n",
    "X, Y, X_train, X_test, y_train, y_test = splitdataset(data) \n",
    "clf_gini = train_using_gini(X_train, X_test, y_train) \n",
    "clf_entropy = train_using_entropy(X_train, X_test, y_train) \n",
    "\n",
    "# Operational Phase \n",
    "print(\"Results Using Gini Index:\") \n",
    "\n",
    "# Prediction using gini \n",
    "y_pred_gini = prediction(X_test, clf_gini) \n",
    "cal_accuracy(y_test, y_pred_gini) \n",
    "\n",
    "print(\"Results Using Entropy:\") \n",
    "# Prediction using entropy \n",
    "y_pred_entropy = prediction(X_test, clf_entropy) \n",
    "cal_accuracy(y_test, y_pred_entropy) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (Normalizing Data)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = ExtraTreesClassifier(n_estimators=64,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color=\"b\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "plt.title(\"Feature Importances\")\n",
    "n=20\n",
    "_ = plt.bar(range(n), importances[indices][:n], color=\"b\", yerr=std[indices][:n])\n",
    "plt.xticks(range(n), indices)\n",
    "plt.xlim([-1, n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This line instantiates the model. \n",
    "rf = RandomForestClassifier(n_estimators=64) \n",
    "## Fits the model on my training data.\n",
    "rf.fit(X_train, y_train) \n",
    "## And scores it on my testing data.\n",
    "y_pred=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Accuracy, how often is the classifier correct?\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(rf, X_train, y_train):\n",
    "    return r2_score(y_train, rf.predict(X_train))\n",
    "\n",
    "perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "perm_imp_rfpimp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
